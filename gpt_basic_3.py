#!/usr/bin/env python3

import random
import threading
import traceback

import openai
from sqlitedict import SqliteDict

import cfg
import my_log


# ROLE = """Ğ¢Ñ‹ Ğ¸ÑĞºÑƒÑÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ¸Ğ½Ñ‚ĞµĞ»Ğ»ĞµĞºÑ‚ Ğ¾Ñ‚Ğ²ĞµÑ‡Ğ°ÑÑ‰Ğ¸Ğ¹ Ğ½Ğ° Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑ‹ ÑĞ·ĞµÑ€Ğ°."""
ROLE = ''
MODEL = 'google/gemma-2-9b-it:free'

# ÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ
MAX_MEM_LINES = 20
MAX_CHARS = 12000

# Ğ±Ğ»Ğ¾ĞºĞ¸Ñ€Ğ¾Ğ²ĞºĞ° Ñ‡Ğ°Ñ‚Ğ¾Ğ² Ñ‡Ñ‚Ğ¾ Ğ±Ñ‹ Ğ½Ğµ Ğ¸ÑĞ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ‚ÑŒ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ 
# {id:lock}
LOCKS = {}

# Ğ½Ğµ Ğ¿Ñ€Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ñ‚ÑŒ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ±Ğ¾Ğ»ÑŒÑˆĞµ Ñ‡ĞµĞ¼, ÑÑ‚Ğ¾ Ğ¾Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ğµ Ğ´Ğ»Ñ Ñ‚ĞµĞ»ĞµĞ³Ñ€Ğ°Ğ¼ Ğ±Ğ¾Ñ‚Ğ°, Ğ² ÑÑ‚Ğ¾Ğ¼ Ğ¼Ğ¾Ğ´ÑƒĞ»Ğµ Ğ¾Ğ½Ğ¾ Ğ½Ğµ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ
MAX_REQUEST = 12000

# Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰Ğµ Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³Ğ¾Ğ² {id:list(mem)}
CHATS = SqliteDict('db/gemma2-9b_dialogs.db', autocommit=True)


def ai(prompt: str = '', temp: float = 0.1, max_tok: int = 4000, timeou: int = 120, messages = None,
       chat_id = None, model_to_use: str = '') -> str:
    """Ğ¡Ñ‹Ñ€Ğ¾Ğ¹ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ñ‹Ğ¹ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ Ğº GPT Ñ‡Ğ°Ñ‚Ñƒ, Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ ÑÑ‹Ñ€Ğ¾Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚
    """
    try:
        if not messages:
            assert prompt != '', 'prompt Ğ½Ğµ Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ±Ñ‹Ñ‚ÑŒ Ğ¿ÑƒÑÑ‚Ñ‹Ğ¼'
            messages = [{"role": "system", "content": ROLE},
                        {"role": "user", "content": prompt}]
        messages += [{"role": "user", "content": prompt}]
        current_model = MODEL

        response = ''

        # ĞºĞ¾Ğ¿Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¸ Ğ¿ĞµÑ€ĞµĞ¼ĞµÑˆĞ¸Ğ²Ğ°ĞµĞ¼ ÑĞ¿Ğ¸ÑĞ¾Ğº ÑĞµÑ€Ğ²ĞµÑ€Ğ¾Ğ²
        shuffled_servers = cfg.openai_servers[:]
        random.shuffle(shuffled_servers)

        for server in shuffled_servers:
            openai.api_base = server[0]
            openai.api_key = server[1]

            try:
                # Ñ‚ÑƒÑ‚ Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ ÑÑ‚ĞµĞ¿ĞµĞ½ÑŒ Ñ‚Ğ²Ğ¾Ñ€Ñ‡ĞµÑÑ‚Ğ²Ğ°(Ğ±Ñ€ĞµĞ´Ğ°) Ğ¾Ñ‚ 0 Ğ´Ğ¾ 1 Ğ´ĞµÑ„Ğ¾Ğ»Ñ‚ - temperature=0.5
                completion = openai.ChatCompletion.create(
                    model = current_model,
                    messages=messages,
                    max_tokens=max_tok,
                    temperature=temp,
                    timeout=timeou
                )
                response = completion.choices[0].message.content
                if response.strip() in ('Rate limit exceeded', 'You exceeded your current quota, please check your plan and billing details.'):
                    response = ''
                if response:
                    break
            except Exception as unknown_error1:
                error_tr = traceback.format_exc()
                my_log.log2(f'gpt_basic_2.ai: {unknown_error1}\n\nServer: {openai.api_base}\n\n{server[1]}\n\n{error_tr}')
        return response
    except Exception as unknown_error2:
        error_tr = traceback.format_exc()
        my_log.log2(f'gpt_basic_2.ai: {unknown_error2}\n\n{error_tr}')
        return ''


def clear_mem(mem):
    while 1:
        sizeofmem = count_tokens(mem)
        if sizeofmem <= MAX_CHARS:
            break
        try:
            mem = mem[2:]
        except IndexError:
            mem = []
            break

    return mem[-MAX_MEM_LINES*2:]


def count_tokens(mem) -> int:
    return sum([len(m['content']) for m in mem])


def update_mem(query: str, resp: str, chat_id: str):
    if chat_id not in CHATS:
        CHATS[chat_id] = []
    mem = CHATS[chat_id]
    mem += [{'role': 'user', 'content': query}]
    mem += [{'role': 'assistant', 'content': resp}]
    mem = clear_mem(mem)

    mem__ = []
    try:
        i = 0
        while i < len(mem):
            if i == 0 or mem[i] != mem[i-1]:
                mem__.append(mem[i])
            i += 1
    except Exception as error:
        error_traceback = traceback.format_exc()
        my_log.log_haiku(f'my_gpt_basic_3:update_mem: {error}\n\n{error_traceback}\n\n{query}\n\n{resp}\n\n{mem}')

    CHATS[chat_id] = mem__


def chat(query: str, chat_id: str = '', temperature: float = 0.1) -> str:
    global LOCKS, CHATS
    if chat_id in LOCKS:
        lock = LOCKS[chat_id]
    else:
        lock = threading.Lock()
        LOCKS[chat_id] = lock
    with lock:
        if chat_id not in CHATS:
            CHATS[chat_id] = []
        mem = CHATS[chat_id]
        text = ai(query, messages=mem, temp = temperature)
        if text:
            update_mem(query, text, chat_id)
        return text


def chat_cli():
    while 1:
        q = input('>')
        if q == 'mem':
            print(get_mem_as_string('test'))
            continue
        r = chat(f'(Ğ¾Ñ‚Ğ²ĞµÑ‡Ğ°Ğ¹ Ğ²ÑĞµĞ³Ğ´Ğ° Ğ½Ğ° ÑĞ·Ñ‹ĞºĞµ [ru]) ' + q, 'test')
        print(r)


def undo(chat_id: str):
    """
    Undo the last two lines of chat history for a given chat ID.

    Args:
        chat_id (str): The ID of the chat.

    Raises:
        Exception: If there is an error while undoing the chat history.

    Returns:
        None
    """
    try:
        global LOCKS, CHATS

        if chat_id in LOCKS:
            lock = LOCKS[chat_id]
        else:
            lock = threading.Lock()
            LOCKS[chat_id] = lock
        with lock:
            if chat_id in CHATS:
                mem = CHATS[chat_id]
                # remove 2 last lines from mem
                mem = mem[:-2]
                CHATS[chat_id] = mem
    except Exception as error:
        error_traceback = traceback.format_exc()
        my_log.log_haiku(f'Failed to undo chat {chat_id}: {error}\n\n{error_traceback}')


def reset(chat_id: str):
    """
    Resets the chat history for the given ID.

    Parameters:
        chat_id (str): The ID of the chat to reset.

    Returns:
        None
    """
    global CHATS
    CHATS[chat_id] = []


def get_mem_as_string(chat_id: str) -> str:
    """
    Returns the chat history as a string for the given ID.

    Parameters:
        chat_id (str): The ID of the chat to get the history for.

    Returns:
        str: The chat history as a string.
    """
    global CHATS
    if chat_id not in CHATS:
        CHATS[chat_id] = []
    mem = CHATS[chat_id]
    result = ''
    for x in mem:
        role = x['role']
        if role == 'user': role = 'ğ”ğ’ğ„ğ‘'
        if role == 'assistant': role = 'ğğğ“'
        if role == 'system': role = 'ğ’ğ˜ğ’ğ“ğ„ğŒ'
        text = x['content']
        if text.startswith('[Info to help you answer'):
            end = text.find(']') + 1
            text = text[end:].strip()
        result += f'{role}: {text}\n'
        if role == 'ğğğ“':
            result += '\n'
    return result 



if __name__ == '__main__':
    # for _ in range(3):
    #     x = random.randint(100, 900)
    #     y = random.randint(100, 900)
    #     print(ai(f'Ñ€ĞµÑˆĞ¸ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€ {x}*{y}, Ğ² Ğ¾Ñ‚Ğ²ĞµÑ‚Ğµ Ğ¿Ğ¾ĞºĞ°Ğ¶Ğ¸ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ Ğ¸ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ñ‚Ğ°Ğº x*y=zzz, Ğ¾Ğ´Ğ½Ğ° ÑÑ‚Ñ€Ğ¾Ñ‡ĞºĞ° Ğ² Ğ¾Ñ‚Ğ²ĞµÑ‚Ğµ Ğ¸ Ğ² Ğ½ĞµĞ¼ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ x*y=zzz'))
    reset('test')
    chat_cli()
